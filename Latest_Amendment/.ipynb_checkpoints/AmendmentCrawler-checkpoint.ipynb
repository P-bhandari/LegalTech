{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browse_Url = https://indiankanoon.org/search/?formInput=title%3A%28Amendment%29%20sortby%3A%20mostrecent%20fromdate%3A%2001-01-1953%20todate%3A%2031-12-1954%20doctypes%3Alaws%2Cjudgments%2C\n",
      "max_page_num = 1\n",
      "############################################\n",
      "Title = The Reserve Bank Of India (Amendment And Miscellaneous Provisions) Act,   1953\n",
      "URL = https://indiankanoon.org/docfragment/1612160/?formInput=title%3A%20%28Amendment%29%20%20doctypes%3A%20judgments%2Claws%20fromdate%3A%201-1-1953%20todate%3A%2031-12-1954%20sortby%3A%20mostrecent\n",
      "Headline = \n",
      "    Central Governm\n",
      "Section = None\n",
      "date = 1953\n",
      "act = The Reserve Bank Of India Act\n",
      "Complete act url = \n",
      "result_act_document_num = 1612160\n",
      "complete_act_document_num = None\n",
      "############################################\n",
      "Title = Section 9 in The Reserve Bank Of India (Amendment And Miscellaneous Provisions) Act,   1953\n",
      "URL = https://indiankanoon.org/doc/1283412/\n",
      "Headline = \n",
      "    Section 9 in Th\n",
      "Section = Section 9\n",
      "date = 1953\n",
      "act = The Reserve Bank Of India Act\n",
      "Complete act url = https://indiankanoon.org/doc/1612160/\n",
      "result_act_document_num = 1283412\n",
      "complete_act_document_num = 1612160\n",
      "############################################\n",
      "Title = Section 1 in The Reserve Bank Of India (Amendment And Miscellaneous Provisions) Act,   1953\n",
      "URL = https://indiankanoon.org/doc/19727/\n",
      "Headline = \n",
      "    Section 1 in Th\n",
      "Section = Section 1\n",
      "date = 1953\n",
      "act = The Reserve Bank Of India Act\n",
      "Complete act url = https://indiankanoon.org/doc/1612160/\n",
      "result_act_document_num = 19727\n",
      "complete_act_document_num = 1612160\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import math\n",
    "def no_results(text):\n",
    "    text = text.lower()\n",
    "    if((text.find(\"no\")>-1) & (text.find(\"matching\")>-1 )& (text.find(\"results\")>-1)):\n",
    "        return True ;\n",
    "    else:\n",
    "        return False;\n",
    "    \n",
    "def get_max_pag_num(text):\n",
    "    index = text.find(\"of\")\n",
    "        \n",
    "    return math.ceil(int(text[index+3:])/9)\n",
    "\n",
    "def get_date(numbers,title):\n",
    "    output = [] ; \n",
    "    for num in numbers:\n",
    "        if((len(num) == 4 )&(int(num[:2])>18 )& (int(num[:2])<21)):\n",
    "            #print(\"found date = \" + num)\n",
    "            output.append(num); \n",
    "    \n",
    "    if((len(output)>1) | (len(output)==0)):\n",
    "        print_trace(title,'get_date'); \n",
    "        return -1 ;\n",
    "    else:\n",
    "        return output[0] ; \n",
    "            \n",
    "#make sure numbers is a list of string\n",
    "#create check for the numbers in list before\n",
    "def get_section(title):\n",
    "    index_section = title.lower().find(\"section\"); \n",
    "    index_in = title.lower().find(\"in\")\n",
    "    if(index_section > -1):\n",
    "        if(index_in > index_section +4):\n",
    "            #something\n",
    "            return title[index_section:index_in-1];\n",
    "        else:\n",
    "            print_trace(title, \"get_section - Cannot find in keyword after section\")\n",
    "            return None ;\n",
    "    else:\n",
    "        return None ;\n",
    "'''\n",
    "#get section number  by searching all the numbers in the title.\n",
    "def get_section(title,numbers):\n",
    "    \n",
    "    index_section = (title.lower()).find(\"section\")\n",
    "    if(index_section > -1):\n",
    "        answer = -1; \n",
    "        distance = 999999; \n",
    "        for num in numbers:\n",
    "            temp_distance = title.lower().find(num) -index_section ;\n",
    "            if(temp_distance < distance):\n",
    "                answer = num ; \n",
    "                distance = temp_distance ;\n",
    "        \n",
    "        return answer;\n",
    "    else:\n",
    "        return  None\n",
    "   ''' \n",
    "def print_trace(title,func):\n",
    "    print(\"Error in Func = \"+func);\n",
    "    print(\"Base_url : \" + base_url); \n",
    "    print(\"Title :\" + title); \n",
    "    print(\"year start = \" + year_start); \n",
    "    print(\"year end = \" + year_end);\n",
    "\n",
    "def get_browse_url(base_url,y_s,y_e,i):\n",
    "    temp =114\n",
    "    base_url = base_url[:temp] + str(int(y_s)+i)+ base_url[temp+4:]\n",
    "    temp =139\n",
    "    base_url = base_url[:temp] + str(int(y_e)+i)+ base_url[temp+4:]\n",
    "    return base_url\n",
    "\n",
    "basic_url = \"https://indiankanoon.org\"\n",
    "base_url = \"https://indiankanoon.org/search/?formInput=title%3A%28Amendment%29%20sortby%3A%20mostrecent%20fromdate%3A%2001-01-1953%20todate%3A%2031-12-1953%20doctypes%3Alaws%2Cjudgments%2C\"\n",
    "year_start = '1953' ; \n",
    "year_end = '1954' ;\n",
    "for i in range(1):#for each advance search page\n",
    "    browse_adv_url = get_browse_url(base_url,year_start,year_end,i);\n",
    "    print(\"Browse_Url = \"+browse_adv_url)\n",
    "    response  = requests.get(browse_adv_url)\n",
    "    if(response.ok==False):\n",
    "        print(\"Http request failed to : \"+base_url)\n",
    "        raise\n",
    "\n",
    "    \n",
    "    browse_amendments = response.text\n",
    "    browse_page = BeautifulSoup(browse_amendments);\n",
    "    temp_num_result_tag =browse_page.find_all(\"div\", {\"class\": \"results_middle\"})\n",
    "    page_results_num_text = temp_num_result_tag[0].find_all(\"b\")[0].text\n",
    "    max_page_num  = -1;\n",
    "    if(no_results(page_results_num_text) == False ):\n",
    "        max_page_num = get_max_pag_num(page_results_num_text)\n",
    "    else:\n",
    "        print_trace(\"\",\"Error :: no_results found in url = \"+browse_adv_url) ;\n",
    "        continue \n",
    "    print( \"max_page_num = \"+str(max_page_num));\n",
    "    for page_num in range(max_page_num):\n",
    "        response  = requests.get(browse_adv_url+\"&pagenum=\"+str(page_num))\n",
    "        if(response.ok==False):\n",
    "            print(\"Http request failed to : \"+base_url)\n",
    "            raise\n",
    "        browse_results_pp = BeautifulSoup(response.text);\n",
    "        temp_num_result_tag_pp =browse_results_pp.find_all(\"div\", {\"class\": \"results_middle\"})\n",
    "        page_results_num_text_pp = temp_num_result_tag_pp[0].find_all(\"b\")[0].text\n",
    "        if(no_results(page_results_num_text_pp) == True ):\n",
    "            print_trace(\"\",\"Error :: no_results found in url = \"+browse_adv_url+\"&pagenum=\"+str(page_num)) ;\n",
    "            continue \n",
    "        results_div = browse_results_pp.find_all(\"div\", {\"class\": \"result\"})\n",
    "        for result_tag in results_div:\n",
    "            print('############################################')\n",
    "            #title\n",
    "            title = result_tag.find_all(\"a\", {\"class\": \"result_url\"})[0].text\n",
    "            if(len(title) == 0):\n",
    "                print(\"\",\"Error:: Title not found url = \"+browse_adv_url+\"&pagenum=\"+str(page_num));\n",
    "            print(\"Title = \"+title);\n",
    "            #title end\n",
    "            \n",
    "            #document url\n",
    "            url = basic_url+result_tag.find_all(\"a\", {\"class\": \"result_url\"})[0].get('href') \n",
    "            print(\"URL = \"+url);\n",
    "\n",
    "            #document url end\n",
    "            \n",
    "            #headline\n",
    "            headline = result_tag.find_all(\"div\",{\"class\":\"headline\"})[0].text\n",
    "            print(\"Headline = \"+headline[:20]);\n",
    "\n",
    "            #headline end\n",
    "            \n",
    "            #section\n",
    "            section = get_section(title)\n",
    "            print(\"Section = \"+str(section));\n",
    "\n",
    "            #section end\n",
    "            \n",
    "            #date\n",
    "            numbers = re.findall('\\d+',title)\n",
    "            date = get_date(numbers,title)\n",
    "            print(\"date = \"+date);\n",
    "\n",
    "            #date end\n",
    "            \n",
    "            #act extraction\n",
    "            temp_s = title\n",
    "            bracket_left = temp_s.lower().find('(')\n",
    "            bracket_right = temp_s.lower().find(')')\n",
    "            temp_act = temp_s.replace(' '+temp_s[bracket_left : bracket_right+1],'')\n",
    "\n",
    "            index_start = temp_act.lower().find('the') ;\n",
    "            index_end = temp_act.lower().find('act')\n",
    "            act = temp_act[index_start:index_end+3]\n",
    "            print(\"act = \"+act);\n",
    "\n",
    "            #act extraction end\n",
    "            \n",
    "            #compete act url extract \n",
    "            a = result_tag.find_all('a')\n",
    "            complete_act_urls_temp = []\n",
    "            complete_act_url =''\n",
    "            for a_ in a:\n",
    "                if((a_.text.lower().find(\"complete\")>-1) & (a_.text.lower().find('act'))):\n",
    "                    complete_act_urls_temp.append(a_.get('href'))\n",
    "            if(len(complete_act_urls_temp)==0):\n",
    "                complete_act_url = '';\n",
    "            elif (len(complete_act_urls_temp)>1):\n",
    "                print_trace(\"\",\"Error:: Complete act number is more than 1 url = \"+browse_adv_url+\"&pagenum=\"+page_numstr(page_num))\n",
    "            else:\n",
    "                complete_act_url =basic_url + complete_act_urls_temp[0]; \n",
    "            print(\"Complete act url = \"+complete_act_url);\n",
    "            #compete act url extract  end\n",
    "            \n",
    "            #compete act & section act document number\n",
    "            if((section == None) & (complete_act_url =='')):\n",
    "                temp_url = url ;\n",
    "                temp_url = temp_url.replace( basic_url+\"/docfragment/\",'')\n",
    "                result_act_document_num = temp_url[:temp_url.find('/')]\n",
    "            else:\n",
    "                result_act_document_num = url[len(basic_url)+5:len(url)-1] ;\n",
    "            complete_act_document_num  = None\n",
    "            if(complete_act_url != ''):\n",
    "                complete_act_document_num =complete_act_url[len(basic_url)+5:len(complete_act_url)-1] ;\n",
    "            print(\"result_act_document_num = \"+result_act_document_num);\n",
    "            print(\"complete_act_document_num = \"+str(complete_act_document_num));\n",
    "            #complete act & section act document number\n",
    "\n",
    "            response_result_act  = requests.get(url)\n",
    "            if(response_result_act.ok==False):\n",
    "                print(\"Http request failed to : \"+base_url)\n",
    "                raise\n",
    "            act_page  = BeautifulSoup(response_result_act.text)\n",
    "            act_text_div = act_page.find_all(\"div\", {\"class\": \"acts\"})\n",
    "            \n",
    "            if(len(act_text_div)>1):\n",
    "                print_trace(title,\"more than 1 act tags found in the url :\"+url)\n",
    "            act_text_all_tags = act_text_div[0].find_all(); \n",
    "            \n",
    "            f  = open(\"Database/\"+str(result_act_document_num)+\".txt\",\"w+\");\n",
    "            \n",
    "            for tag in act_text_all_tags:\n",
    "                f.write(tag.text);\n",
    "                f.write('\\n');\n",
    "                f.write('\\n');\n",
    "            f.close(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_page_num = get_max_pag_num(temp[0].find_all(\"b\")[0].text)\n",
    "##for loop for the pages\n",
    "#if condition on the no results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_div = browse_page.find_all(\"div\", {\"class\": \"result\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found date = 1953\n"
     ]
    }
   ],
   "source": [
    "#extract title\n",
    "#check for 1 length\n",
    "title = results_div[0].find_all(\"a\", {\"class\": \"result_url\"})[0].text\n",
    "#check if title contains amendment, if not don't parse it but store it someplace else.\n",
    "url = basic_url+results_div[0].find_all(\"a\", {\"class\": \"result_url\"})[0].get('href') \n",
    "headline = results_div[0].find_all(\"div\",{\"class\":\"headline\"})[0].text\n",
    "numbers = re.findall('\\d+',title)\n",
    "section = get_section(title)\n",
    "#check if section is None\n",
    "date = get_date(numbers,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#act extraction\n",
    "temp_s = title\n",
    "bracket_left = temp_s.lower().find('(')\n",
    "bracket_right = temp_s.lower().find(')')\n",
    "temp_act = temp_s.replace(' '+temp_s[bracket_left : bracket_right+1],'')\n",
    "\n",
    "index_start = temp_act.lower().find('the') ;\n",
    "index_end = temp_act.lower().find('act')\n",
    "act = temp_act[index_start:index_end+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for every results_div\n",
    "a = results_div[1].find_all('a')\n",
    "complete_act_url = []\n",
    "for a_ in a:\n",
    "    if((a_.text.lower().find(\"complete\")>-1) & (a_.text.lower().find('act'))):\n",
    "        complete_act_url.append(a_.get('href'))\n",
    "#check for complete_act_url length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "response  = requests.get(url)\n",
    "if(response.ok==False):\n",
    "    print(\"Http request failed to : \"+base_url)\n",
    "    raise\n",
    "act_page  = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_text_div = act_page.find_all(\"div\", {\"class\": \"acts\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(len(act_text_div)>1):\n",
    "    print_trace(title,\"more than 1 act tags found in the url :\"+url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_text_all_tags = act_text_div[0].find_all(); \n",
    "#parse all the tags and save it in a file _ Also save the act_text_all_tags in a seperate file\n",
    "#do this same for the complete act url\n",
    "#save the html part of each of these acts and complete acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"article\" id=\"9\"> <a href=\"/doc/1283412/\">9.</a>  Ordinance 3 of  1946  not to apply to certain high denomination bank notes.- Nothing contained in the High Denomination Bank Notes (Demonetisation) Ordinance,  1946  (3 of  1946  ) shall apply to any bank note of the denominational value of five hundred rupees, one thousand rupees or ten thousand rupees issued after the commencement of this Act, but no such bank note issued before the 13th day of January,  1946  (3 of  1946  ) shall be legal tender in payment or on account of the amount expressed therein at any place in India.</div>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
